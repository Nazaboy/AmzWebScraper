{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "import datetime\n",
    "import smtplib\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- requests handling\n",
    "\n",
    "some collected infos:\n",
    "- The User-Agent request header is a characteristic string that lets servers and network peers identify the application, operating system, vendor, and/or version of the requesting user agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: B09843WY1B\n",
      "Product Name:         Johnson's Baby Cotton Buds 100s (Pack of 12)       \n",
      "Description: Gentle for use in delicate areas around the eyes and the outer ear    Cleans in between baby’s fingers, toes and other creases on the skin    Naturally absorbent with 100% pure cotton tips    100% paper sticks    Plastic-free recyclable packaging\n",
      "Store: Amazon UK\n",
      "Rating: 4.7  4.7 out of 5 stars    \n",
      "    22,801 ratings\n",
      "\n",
      "Size: 100 Count (Pack of 12)\n",
      "Price: 5 options from £13.60\n",
      "\n",
      "Size: 200 Count (Pack of 1)\n",
      "Price: 5 options from £3.49\n",
      "\n",
      "Size: 200 Count (Pack of 3)\n",
      "Price: £3.75\n",
      "\n",
      "Size: Small\n",
      "Price: 2 options from £3.69\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URL and headers\n",
    "URL = 'https://www.amazon.co.uk/Johnsons-Cotton-Buds-200/dp/B09843WY1B/ref=zg_bs_g_baby_d_sccl_3/257-9862628-6554964'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fetching the page content\n",
    "page = requests.get(URL, headers=headers)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Extracting product details\n",
    "product_id = URL.split('/dp/')[1].split('/')[0]  # Extract product ID from URL\n",
    "product_title = soup.find(id='productTitle').get_text()\n",
    "product_description = soup.find(id='feature-bullets').get_text().strip() if soup.find(id='feature-bullets') else 'Description not available'\n",
    "store = 'Amazon UK'  # Store name, generally static for Amazon\n",
    "rating = soup.find(id='averageCustomerReviews').get_text().strip() if soup.find(id='averageCustomerReviews') else 'Rating not available'\n",
    "\n",
    "# Initialize variables\n",
    "i = 0\n",
    "size_price_dict = {}\n",
    "\n",
    "while True:\n",
    "    # Try to find size and price elements by their IDs\n",
    "    size_id = f'size_name_{i}'\n",
    "    price_id = f'size_name_{i}_price'\n",
    "    \n",
    "    size_element = soup.find(id=size_id)\n",
    "    price_element = soup.find(id=price_id)\n",
    "    \n",
    "    # Break the loop if no more sizes or prices are found\n",
    "    if not size_element or not price_element:\n",
    "        break\n",
    "    \n",
    "    # Get and clean text\n",
    "    size = size_element.get_text().strip().split(\"\\n\")[0].strip()  # Split by line and take the first part\n",
    "    price = price_element.get_text().strip().replace(\"1 option from \", \"\").strip()\n",
    "    \n",
    "    # Add to dictionary\n",
    "    size_price_dict[size] = price\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "# Print product details\n",
    "print(f\"Product ID: {product_id}\")\n",
    "print(f\"Product Name: {product_title}\")\n",
    "print(f\"Description: {product_description}\")\n",
    "print(f\"Store: {store}\")\n",
    "print(f\"Rating: {rating}\\n\")\n",
    "\n",
    "# Print the size and price dictionary\n",
    "for size, price in size_price_dict.items():\n",
    "    print(f\"Size: {size}\\nPrice: {price}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: B07V2N4SJY\n",
      "Product Name: Amazon Brand – Mama Bear Sensitive Unscented Baby Wipes, 1008 Count (18 Packs of 56)\n",
      "Description: About this item    MULTI-BENEFIT PACK: 18 packs; 56 water-based wipes per pack    PERFUME FREE: Fragrance-free, pre-moistened wipes    FOR SENSITIVE SKIN: Gently formulated and hypoallergenic for baby's delicate skin    VERSATILE: For hands, face and the diaper area    SOOTHING INGREDIENTS: Made with aloe vera and chamomile    RECOMMENDED BY DERMATOLOGISTS: Dermatologically approved, balanced pH value\n",
      "Store: Amazon UK\n",
      "Rating: 4.8  4.8 out of 5 stars    \n",
      "    25,825 ratings\n",
      "\n",
      "Size: 56 count (Pack of 6)\n",
      "Price: £5.17\n",
      "\n",
      "Size: 56 count (Pack of 18)\n",
      "Price: £13.65\n",
      "\n",
      "Size: 64 count (Pack of 12)\n",
      "Price: £11.44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# URL and headers\n",
    "URL = 'https://www.amazon.co.uk/Amazon-Brand-Sensitive-Unscented-wipes/dp/B07V2N4SJY/ref=zg_bs_g_baby_d_sccl_1/257-9862628-6554964?psc=1'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Fetching the page content\n",
    "page = requests.get(URL, headers=headers)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "# Extracting product details\n",
    "product_id = URL.split('/dp/')[1].split('/')[0]  # Extract product ID from URL\n",
    "product_title = soup.find(id='productTitle').get_text().strip()\n",
    "product_description = soup.find(id='feature-bullets').get_text().strip() if soup.find(id='feature-bullets') else 'Description not available'\n",
    "store = 'Amazon UK'  # Store name, generally static for Amazon\n",
    "rating = soup.find(id='averageCustomerReviews').get_text().strip() if soup.find(id='averageCustomerReviews') else 'Rating not available'\n",
    "\n",
    "# Initialize variables\n",
    "i = 0\n",
    "size_price_dict = {}\n",
    "\n",
    "while True:\n",
    "    # Try to find size and price elements by their IDs\n",
    "    size_id = f'size_name_{i}'\n",
    "    price_id = f'size_name_{i}_price'\n",
    "    \n",
    "    size_element = soup.find(id=size_id)\n",
    "    price_element = soup.find(id=price_id)\n",
    "    \n",
    "    # Break the loop if no more sizes or prices are found\n",
    "    if not size_element or not price_element:\n",
    "        break\n",
    "    \n",
    "    # Get and clean text\n",
    "    size = size_element.get_text().strip().split(\"\\n\")[0].strip()  # Split by line and take the first part\n",
    "    price = price_element.get_text().strip().replace(\"1 option from \", \"\").strip()\n",
    "    \n",
    "    # Add to dictionary\n",
    "    size_price_dict[size] = price\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "# Print product details\n",
    "print(f\"Product ID: {product_id}\")\n",
    "print(f\"Product Name: {product_title}\")\n",
    "print(f\"Description: {product_description}\")\n",
    "print(f\"Store: {store}\")\n",
    "print(f\"Rating: {rating}\\n\")\n",
    "\n",
    "# Print the size and price dictionary\n",
    "for size, price in size_price_dict.items():\n",
    "    print(f\"Size: {size}\\nPrice: {price}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed https://www.amazon.co.uk/Amazon-Brand-Sensitive-Unscented-wipes/dp/B07V2N4SJY/ref=zg_bs_g_baby_d_sccl_1/257-9862628-6554964?psc=1\n",
      "Processed https://www.amazon.co.uk/WaterWipes-Sensitive-Newborn-Biodegradable-Unscented/dp/B08MXSBRSB/ref=zg_bs_g_baby_d_sccl_2/257-9862628-6554964?psc=1\n"
     ]
    }
   ],
   "source": [
    "def fetch_page(url, headers):\n",
    "    \"\"\"Fetches the page content from the given URL.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Check for HTTP request errors\n",
    "        return response.content\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching page: {e}\")\n",
    "        return None\n",
    "\n",
    "def extract_text(element, default='Not available'):\n",
    "    \"\"\"Safely extracts text from a BeautifulSoup element.\"\"\"\n",
    "    return element.get_text(strip=True) if element else default\n",
    "\n",
    "def extract_product_details(soup, product_id):\n",
    "    \"\"\"Extracts product details from BeautifulSoup object.\"\"\"\n",
    "    product_title = extract_text(soup.find(id='productTitle'))\n",
    "    description_element = soup.find('div', {'id': 'feature-bullets'})\n",
    "    product_description = extract_text(description_element)\n",
    "    rating_element = soup.find(id='averageCustomerReviews')\n",
    "    rating = extract_text(rating_element)\n",
    "    return product_title, product_description, rating\n",
    "\n",
    "def extract_size_price(soup):\n",
    "    \"\"\"Extracts sizes and prices from BeautifulSoup object.\"\"\"\n",
    "    size_price_dict = {}\n",
    "    i = 0\n",
    "    while True:\n",
    "        size_id = f'size_name_{i}'\n",
    "        price_id = f'size_name_{i}_price'\n",
    "        \n",
    "        size_element = soup.find(id=size_id)\n",
    "        price_element = soup.find(id=price_id)\n",
    "        \n",
    "        if not size_element or not price_element:\n",
    "            break\n",
    "        \n",
    "        size = extract_text(size_element).split(\"\\n\")[0].strip()\n",
    "        price = extract_text(price_element).replace(\"1 option from \", \"\").strip()\n",
    "        \n",
    "        size_price_dict[size] = price\n",
    "        i += 1\n",
    "    return size_price_dict\n",
    "\n",
    "def scrape_and_save(urls, headers, output_file):\n",
    "    \"\"\"Scrapes product details from multiple URLs and saves results to a CSV file.\"\"\"\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Product ID', 'Product Name', 'Description', 'Store', 'Rating', 'Size', 'Price']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        \n",
    "        for url in urls:\n",
    "            page_content = fetch_page(url, headers)\n",
    "            if page_content:\n",
    "                soup = BeautifulSoup(page_content, \"html.parser\")\n",
    "                product_id = url.split('/dp/')[1].split('/')[0]\n",
    "                product_title, product_description, rating = extract_product_details(soup, product_id)\n",
    "                size_price_dict = extract_size_price(soup)\n",
    "                \n",
    "                for size, price in size_price_dict.items():\n",
    "                    writer.writerow({\n",
    "                        'Product ID': product_id,\n",
    "                        'Product Name': product_title,\n",
    "                        'Description': product_description,\n",
    "                        'Store': 'Amazon UK',\n",
    "                        'Rating': rating,\n",
    "                        'Size': size,\n",
    "                        'Price': price\n",
    "                    })\n",
    "                print(f\"Processed {url}\")\n",
    "\n",
    "# Example usage\n",
    "urls = [\n",
    "    'https://www.amazon.co.uk/Amazon-Brand-Sensitive-Unscented-wipes/dp/B07V2N4SJY/ref=zg_bs_g_baby_d_sccl_1/257-9862628-6554964?psc=1',\n",
    "    'https://www.amazon.co.uk/WaterWipes-Sensitive-Newborn-Biodegradable-Unscented/dp/B08MXSBRSB/ref=zg_bs_g_baby_d_sccl_2/257-9862628-6554964?psc=1',\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/127.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
    "output_file = 'products.csv'\n",
    "scrape_and_save(urls, headers, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
